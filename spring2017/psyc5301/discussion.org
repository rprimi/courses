#+TITLE: Discussion Questions - PSYC 5301
#+AUTHOR:
#+DATE: Spring 2017 
#+OPTIONS: toc:nil num:nil

* Week 2 (January 24, 2017)
1. In Chapter 1, Bausell lists 5 principles for conducting scientific research in psychology.  Which of these principles do YOU feel is most important?  Explain your reasoning.

2. In Chapter 2, Bausell introduces the logical fallacy known as "post hoc, ergo propter hoc".  What does this mean?  Give an example in your field of interest of how such reasoning could occur and why it is invalid. 

3. In your research career, you will likely be performing many studies.  Thus, it is important to get a feel for how often you should expect "significant" results.  This question is designed to help introduce you to such thinking.  Note that each problem has a definite mathematical solution, but I am not necessarily looking for this.  Instead, I am wanting to work on your statistical intuitions.
  - Suppose you design a study that tests a null hypothesis H0 that is known to be TRUE (that is, there is no effect), and you replicate this study 100 times.  For how many of those replications would you expect a significant result (i.e., a p-value less than 0.05)?  Explain.
  - Suppose instead that your null hypothesis H0 is known to be FALSE (that is, there is a real effect), and suppose further that your sample size gives you 50% power.  For how many of the 100 replications would you expect a significant result?  Explain.
  - Suppose you design a study with 80% power that is designed to test a null hypothesis H0 with unknown truth (that is, H0 and H1 are equally likely to be true).  Which of the following experimental outcomes do you think is most likely to occur: finding a significant result, or finding a nonsignificant result?  Explain.
* Week 4 (February 7, 2017)
1. In Chapter 4, Bausell lists 10 experimental artifacts that seriously undermine the internal validity of the single-group pretest-posttest design.  Thinking ahead to your own thesis (or applied project), which of these do you think might be the most important for you to consider?  How might you eliminate this artifact in your study?

2. Suppose you are testing a hypothesis H1.  The prior literature indicates that, a priori, this hypothesis is 3 times more likely than the null H0.  Suppose further that you have 80% power and set alpha = 0.05.  What is the probability that you will make a Type I error? 

3. Suppose that for your thesis, you propose to collect data from 100 individuals.  However, data collection is running pretty slowly (it is late spring, after all, and a lot of the undergraduate participant pool is slowly dying from the pressure of papers, finals, and the Larry Joe Taylor festival).  So, after running your 50th participant, your advisor recommends that you run the data and see if you have a significant effect.  You don't, but it is close (p=0.062).  So, you collect 5 more participants and check then.  Now, you have a significant effect (p=0.034).  You and your advisor decide to stop data collection and write up the results for publication.

a.  Does stopping at 55 participants (instead of running the planned 100) affect the probability that you've made a Type I error?  Why/why not?

b.  Do you think the results would change if you continued data collection and ran all 100 participants?  That is, do you think your conclusions about the presence of an effect would differ?  Explain.

c.  Is your advisor promoting good research practice?  Why/why not?

* Week 6 (February 21, 2017)
1.  As you read in Chapter 5 of Bausell, randomization is an integral, necessary part of any experimental design.  

a.  Why is randomization necessary in order to infer a causal relationship from an experiment?

b.  Suppose you design an experiment to test for a difference in test scores between two groups A and B.  In order to properly design your experiment, you propose to randomly assign 100 participants to these two groups.  Find and describe two different methods for performing this randomization procedure.  Discuss the advantages/disadvantages of your two methods.  Hint: Bausell mentions at least one online randomization calculator...start here, but try find two other methods.

2.  The last few weeks, we have been thinking about what p-values we should expect when the null is true (i.e., no effect).  This week, we will think about what we should expect when the null is false (i.e., there is an effect).

Suppose you design an experiment for your thesis that has extremely high power (e.g., 95% power).  Suppose further that after collecting data from all of your planned 100 subjects, you get a p-value of 0.045.  Given your background in null-hypothesis significance testing, you decide to reject the null and conclude that you have a significant effect.

One of your committee members (who may or may not have the initials TJF) counters with an argument that your obtained p-value actually lends more evidence for the null than the alternative.  How do you respond?
* Week 8 (March 7, 2017)
No discussion this week..give CITI training and IRB assignment
* Week 9 (March 22, 2017)

1.  This week, you'll read Bausell, Chapters 6 and 7.  After your reading, consider the following questions:

a. Give an example of an experiment with two between-subjects independent variables (for simplicity, assume they each only have two levels).  Discuss the advantages of employing a factorial design over performing two separate between-subject tests.

b. Is it possible to have an interaction with no main effects?  Explain, giving an example if necessary. 

2. Suppose that after reading some literature, you have come across a truly remarkable finding.  This finding, originally due to Bargh, Chen, and Burrows (1996), revealed that social primes could result in activation of stereotyped behavior.  For example, participants for whom an elderly stereotype was primed (e.g., "old", "lonely", bitter") tended to walk more slowly down the hallway when leaving the experiment than did control participants, a behavior which was consistent with the elderly stereotype!

Amazed by this, you search for more literature on this "elderly priming" phenomenon and collect a table of p-values for a list of elderly priming effects:

| Article                                              | Study | p-value |
|------------------------------------------------------+-------+---------|
| Aarts & Dijksterhuis (2002)                          |    1a |   0.028 |
|                                                      |    1b |   0.041 |
|                                                      |    2a |   0.032 |
|                                                      |    2b |   0.015 |
| Bargh, Chen, & Burrows (1996)                        |    2a |   0.008 |
|                                                      |    2b |   0.039 |
| Cesario, Plaks, & Higgins (2006)                     |     1 |   0.047 |
|                                                      |     2 |   0.019 |
| Dijksterhuis, Aarts, Bargh, & van Knippenberg (2000) |     1 |   0.048 |
|                                                      |     2 |   0.046 |
| Dijksterhuis, Spears, & Lepanasse (2001)             |     1 |   0.042 |
|                                                      |     2 |  0.0006 |
|                                                      |     3 |   0.044 |
| Kawakami, Young, & Dovidio (2002)                    |     1 |   0.017 |
|                                                      |     2 |   0.033 |
| Ku, Wang, & Galinksy (2010)                          |     2 |   0.046 |
|                                                      |     3 |   0.034 |
| Mussweiler (2006)                                    |     2 | 0.043   |


Given this extensive survey of the literature, discuss the evidence for "elderly priming".  Are you convinced that this is a real effect?  Would you expect to find significant results if you replicated one of these experiments?  Why/why not?
