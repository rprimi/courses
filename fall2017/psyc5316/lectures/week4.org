#+TITLE: Week 4 lecture notes - PSYC 5316
#+AUTHOR:
#+DATE: September 18, 2017 
#+OPTIONS: toc:nil num:nil
#+LATEX_HEADER: \usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
#+LATEX_HEADER: \usepackage{amsmath}

Let's begin with an example.  A researcher claims that on a test of open-mindedness, the population mean for adult men is at least 50.  As a check on this claim, imagine that 10 adult males are randomly sampled and their scores on the measure are:

#+BEGIN_SRC
scores = c(25, 60, 43, 56, 32, 43, 47, 59, 39, 41)
#+END_SRC

A quick computation (=mean(scores)=) shows that $\overline{x}=44.5$.  Does this make the claim that $\mu \geq 50$ unreasonable?

Note that we can address this question using confidence intervals.  To construct a 95% confidence interval, we compute the following:

\[
\overline{x}-c\frac{s}{\sqrt{n}}, \overline{x}+c\frac{s}{\sqrt{n}}
\]

The relevant R commands for this problem would be:

#+BEGIN_SRC
xbar = mean(scores)
s = sd(scores)
n=length(scores)
c = qt(0.975,df=n-1)
#+END_SRC

Thus, we can easily compute the confidence interval as:

#+BEGIN_SRC
xbar - c*s/sqrt(n) # lower limit
xbar + c*s/sqrt(n) # upper limit
#+END_SRC

Hence, we are 95% confident that the true population mean $\mu$ is somewhere between 36.3 and 52.7.  As a result, it is not unreasonable to believe $\mu\geq 50$.

Confidence intervals can be used to test hypotheses in this way.  However, there is a different way that is a bit more common in the behavioral sciences.  The method we will describe today was originally developed by Neyman and Pearson in 1933.

* Hypothesis Testing (Neyman-Pearson)

The goal in NP hypothesis testing is to find a /decision rule/ about whether to accept or reject a *null hypothesis*.  If one decides to reject the null hypothesis, the researcher concludes that the *alternative hypothesis* is accepted.

Example: in the preceding example, our null hypothesis would be $H_0:\mu<50$, and our alternative hypothesis would be $H_1:\mu\geq 50$.  

  - note: the null hypothesis $H_0$ is typically set to be the *opposite* of what you predict.

Since NP hypothesis testing involves making a decision, there is always a possibility of making an error.

Definition: A *Type I error* occurs when we reject a true null hypothesis.  The probability of making a Type I error is $\alpha$, which we often call the /level of significance/.

Now, we are in a position to define exactly how NP hypothesis testing works.

** The NP Hypothesis Test
Let $\mu_0$ be some specified value and consider the goal of testing $H_0:\mu\geq \mu_0$ such that the Type I error probability is $\alpha$.  Then we compute:

\[
z=\frac{\overline{x}-\mu_0}{\sigma / \sqrt{n}}
\]

/Decision rule/:  we *reject* the null hypothesis $H_0$ if $z\leq c$, where $c$ is the $\alpha$ quantile of the standard normal distribution.

** Example 1
Let's perform an NP hypothesis test on the data above.  Suppose that we know that the population standard deviation is $\sigma=12$. 

  - Step 1 -- set $H_0: \mu\geq 50$ (so $\mu_0=50$).
  - Step 2 -- set $\alpha=0.05$ (this is pretty common) 
  - Step 3 -- compute $z$:

\[
z=\frac{\overline{x}-\mu_0}{\sigma / \sqrt{n}} = \frac{44.5-50}{12 / \sqrt{10}} = -1.45
\]

  - Step 4 -- compute $c$ (this is often called the "critical value")

#+BEGIN_SRC
qnorm(0.05)
#+BEGIN_SRC

  - Step 5 -- compare $z$ to $c=-1.645$.  Because $z=-1.45$ is greater than $c=-1.645$, we fail to reject $H_0$ and conclude that $\mu \geq 50$.

These steps are a little easier to digest if we can visualize how everything fits together graphically.  Fortunately, this is not too hard to accomplish in R.

#+BEGIN_SRC
shadedTails <- function(from, to, density, ..., col="red"){
  y_seq = seq(from, to, length.out=500)
  d = c(0, density(y_seq, ...), 0)
  polygon(c(from, y_seq, to), d, col=col, density=50)
}
  
x=seq(-4,4,0.01)
plot(x,dnorm(x),type="l",xlab="z-score")
shadedTails(-4, -1.645, dnorm)
points(x=-1.45, y=0.01, lwd=2)
#+END_SRC

The first bit of code defines a convenient function for us to use for the remainder of the lecture.  The second bit produces a plot with a red shaded region and a circle.  The red region is the "rejection region", and the circle represents our sample.  Notice that the sample is outside the rejection region, which tells us that we don't reject the null hypothesis.

file:figures/week4/rejectionRegion.png

** Example 2
Suppose SAT math scores are normally distributed with $\mu=580$ and $\sigma=50$.  You have developed a new training course and want to empirically determine its efficacy.  Your sample of 20 students attains an average score of 610.  Is this a significant increase?

  - Step 1 -- set $H_0: \mu \leq 580$ (we hypothesize an increase, so our null is opposite of this; a decrease)
  - Step 2 -- set $\alpha=0.01$ (we want to be really sure!) 
  - Step 3 -- compute $z$:

\[
z=\frac{\overline{x}-\mu_0}{\sigma / \sqrt{n}} = \frac{610-580}{50 / \sqrt{20}} = 2.68
\]

  - Step 4 -- compute $c$ (this is often called the "critical value")

#+BEGIN_SRC
qnorm(0.99) # this is because we want to be in upper 1%
#+END_SRC

  - Step 5 -- compare $z$ to $c=2.33$.  Because $z=2.68$ is greater than $c=2.33$, we reject $H_0$ and conclude that $\mu \geq 580$.

The visualization of this hypothesis test is as follows:

#+BEGIN_SRC
x=seq(-4,4,0.01)
plot(x,dnorm(x),type="l",xlab="z-score")
shadedTails(2.33, 4, dnorm)
points(x=2.68, y=0.01, lwd=2)
#+END_SRC

file:figures/week4/example2.png
