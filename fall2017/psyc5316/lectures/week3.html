<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<title>Week 3 lecture notes - PSYC 5316</title>
<!-- 2017-10-31 Tue 10:41 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="generator" content="Org-mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center; }
  .todo   { font-family: monospace; color: red; }
  .done   { color: green; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.right  { text-align: center;  }
  th.left   { text-align: center;   }
  th.center { text-align: center; }
  td.right  { text-align: right;  }
  td.left   { text-align: left;   }
  td.center { text-align: center; }
  dt { font-weight: bold; }
  .footpara:nth-child(2) { display: inline; }
  .footpara { display: block; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/javascript" src="http://orgmode.org/mathjax/MathJax.js"></script>
<script type="text/javascript">
<!--/*--><![CDATA[/*><!--*/
    MathJax.Hub.Config({
        // Only one of the two following lines, depending on user settings
        // First allows browser-native MathML display, second forces HTML/CSS
        //  config: ["MMLorHTML.js"], jax: ["input/TeX"],
            jax: ["input/TeX", "output/HTML-CSS"],
        extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js",
                     "TeX/noUndefined.js"],
        tex2jax: {
            inlineMath: [ ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"], ["\\begin{displaymath}","\\end{displaymath}"] ],
            skipTags: ["script","noscript","style","textarea","pre","code"],
            ignoreClass: "tex2jax_ignore",
            processEscapes: false,
            processEnvironments: true,
            preview: "TeX"
        },
        showProcessingMessages: true,
        displayAlign: "center",
        displayIndent: "2em",

        "HTML-CSS": {
             scale: 100,
             availableFonts: ["STIX","TeX"],
             preferredFont: "TeX",
             webFont: "TeX",
             imageFont: "TeX",
             showMathMenu: true,
        },
        MMLorHTML: {
             prefer: {
                 MSIE:    "MML",
                 Firefox: "MML",
                 Opera:   "HTML",
                 other:   "HTML"
             }
        }
    });
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Week 3 lecture notes - PSYC 5316</h1>
<p>
In studies, our data amounts to a <i>sample</i> of a population.  Based on our work in Week 2, we know that the <b>sample mean</b> \(\overline{x}\) is the maximum likelihood estimator of the population mean \(\mu\) (assuming a normal distribution as our model).  However, \(\overline{x}\) is still an <b>estimate</b>, which means there is uncertainty in our measurement
</p>

<p>
Goal: develop a method that will give us a <b>range</b> of values for \(\mu\) based on the available data \(\overline{x}\)
</p>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Sampling distributions</h2>
<div class="outline-text-2" id="text-1">
<p>
Definition: a <b>sampling distribution</b> for an estimator is the probability distribution for the values of that estimator.
</p>

<p>
Example: this week we will work exclusively with the sampling distribution for the <i>sample mean</i>, denoted \(\overline{X}\).
</p>
<ul class="org-ul">
<li>Note: the notation can be confusing, so let's be very specific:
<ul class="org-ul">
<li>\(\overline{x}\) denotes the sample mean (an <i>estimator</i>)
</li>
<li>\(\overline{X}\) denotes the sampling <i>distribution</i>
</li>
</ul>
</li>
</ul>
</div>


<div id="outline-container-sec-1-1" class="outline-3">
<h3 id="sec-1-1">simulation of sampling distribution using R</h3>
<div class="outline-text-3" id="text-1-1">
<p>
We can simulate sampling distributions in R.  Below is some code that you can play with, but lets first understand the logic of the code.  For this simulation, lets assume our sample size is \(n=25\).  Then, the basic loop is as follows:
</p>

<ol class="org-ol">
<li>take a sample of size 25 from the population.  Here, we'll assume that the population is normal with mean 50 and standard deviation 20.
</li>

<li>compute the sample mean \(\overline{x}\) of this sample
</li>
<li>store the mean in a vector
</li>
<li>do this a bunch of times (we'll do 5000 loops).
</li>
</ol>

<p>
Here is the code that accomplishes these steps:
</p>

<pre class="example">
N = 5000
Xbar=rep(0,N)
for (i in 1:N){
  Xsamp=rnorm(n=25, mean=50, sd=25)
  Xbar[i]=mean(Xsamp)
}
</pre>

<p>
Now, <code>Xbar</code> is a vector of 5000 sample means, which we can do all kinds of things with.  First, let's plot its density.  For comparison, we'll plot both the population density AND the sampling distribution together:
</p>

<pre class="example">
par(mfrow=c(2,1))
x=seq(-50,150,0.1)
plot(x,dnorm(x, mean=50, sd=25), type="l")
plot(density(Xbar),xlim=c(-50,150))
</pre>


<div class="figure">
<p><img src="figures/week3/samp.png" alt="samp.png" />
</p>
</div>

<p>
You might immediately notice a few things:
</p>
<ol class="org-ol">
<li>the sampling distribution appears normally distributed
</li>
<li>the mean of the sampling distribution is equal to the mean of the population
</li>
<li>the standard deviation of the sampling distribution is <b>much less</b> than the population standard deviation.
</li>
</ol>

<p>
We can check claims 2 and 3 easily:
</p>

<pre class="example">
mean(Xbar)
sd(Xbar)
</pre>

<p>
You should discover that the mean of \(\overline{X}\) is also approximately equal to 50, and the standard deviation of \(\overline{X}\) is approximately 5.  This is no accident, as is nicely summarized in the following:
</p>

<p>
Fact: when randomly sampling from a normal distribution, we have:
</p>
<ul class="org-ul">
<li>the sampling distribution \(\overline{X}\) is normal 
</li>
<li>\(E(\overline{x})=\mu\)
</li>
<li>\(\sigma_{\overline{X}} = \frac{\sigma}{\sqrt{n}}\), where \(n\) = sample size
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-1-2" class="outline-3">
<h3 id="sec-1-2">computing probabilities of samples</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Consider an experiment that was designed to understand the effect of ozone on weight gain in rats. Suppose that weight gain in rats is normally distributed with \(\mu=14\) and \(\sigma=6\).
</p>

<p>
Suppose further that we test 22 randomly sampled rats.  We administer an ozone "treatment" to these rats and then subsequently measure their weight gain.  We find that \(\overline{x}=11\).
</p>

<p>
Is it reasonable to expect a sample mean of \(\overline{x}=11\) from the parent population?  Why/why not?
</p>

<p>
To solve this, think back to our work above.  Can we describe the distribution of sample means (assuming a sample size of \(n=22\))?
</p>

<ul class="org-ul">
<li>the sampling distribution \(\overline{X}\) is normally distributed
</li>
<li>\(\mu_{\overline{X}}=22\)
</li>
<li>\(\sigma_{\overline{X}} = \frac{\sigma}{\sqrt{n}} = \frac{6}{\sqrt{22}} = 1.279\) 
</li>
</ul>

<p>
Based on this, we can use the <code>pnorm</code> function to compute the probability of obtaining a sample mean of 11 or less.
</p>

<pre class="example">
pnorm(11, mean=14, sd=1.279)
</pre>

<p>
We find that the probability of obtaining a sample mean of 11 or smaller is low.  Specifically, \(p(\overline{x}\leq 11)=0.0095\).
</p>
</div>

<div id="outline-container-sec-1-2-1" class="outline-4">
<h4 id="sec-1-2-1">Alternative: transform to \(z\)-scores</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
A more classical approach to this problem is to transform the raw data to a \(z\)-score.  Recall that if \(X\) is normally distributed with mean \(\mu\) and standard deviation \(\sigma\), we can <b>standardize</b> \(X\) via the transformation:
</p>

<p>
\[
Z=\frac{X-\mu}{\sigma}
\]
</p>

<p>
This <b>standard normal distribution</b> has mean 0 and standard deviation 1, and is the basis of all normal tables in the back of textbooks.
</p>

<p>
Another advantage of transforming to a \(z\) score is that the <code>pnorm</code> computation is very easy!
</p>

<p>
In our example above (the rats), we could do the following:
</p>

<ol class="org-ol">
<li>convert the raw score \(\overline{x}=11\) to a \(z\)-score:
</li>
</ol>

<p>
\[
z=\frac{\overline{x}-\mu_{\overline{X}}}{\sigma_{\overline{X}}}=\frac{\overline{x}-\mu}{\sigma/\sqrt{n}} = \frac{11-14}{6/\sqrt{22}} = -2.35
\]
</p>

<ol class="org-ol">
<li>compute \(p(z\leq -2.345)\)
</li>
</ol>

<pre class="example">
pnorm(-2.345)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Confidence interval of population mean</h2>
<div class="outline-text-2" id="text-2">
<p>
For this section, we will assume that all parent distributions are normal.  We'll cover non-normality later.
</p>
</div>

<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1">Case 1: assume \(\sigma\) is known</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Recall from above that \(Z=\frac{\overline{X}-\mu}{\sigma/\sqrt{x}}\) has a standard normal distribution.  Specifically, this gives us a few known facts about \(Z\).  In particular:
</p>

<ul class="org-ul">
<li>\(p(-1.96 \leq Z \leq 1.96) = 0.95\)
</li>
</ul>

<p>
Note: you can verify this claim in R:
</p>

<pre class="example">
pnorm(1.96)-pnorm(-1.96)
</pre>

<p>
Let's work further with this.  If we substitute the expression for \(Z\), we get 
</p>

<p>
\[
p\Biggl( -1.96 \leq \frac{\overline{X}-\mu}{\sigma/\sqrt{n}} \leq 1.96\Biggr) = 0.95
\]
</p>

<p>
We can rearrange terms in this inequality to express it in terms of \(\mu\):
</p>

<p>
\[
p\Biggl( \overline{X}-1.96\frac{\sigma}{\sqrt{n}} \leq \mu \leq \overline{X}+1.96\frac{\sigma}{\sqrt{n}}\Biggr) = 0.95
\]
</p>

<p>
This is nice, because it says that even though we don't know the exact value of the population mean \(\mu\), we know there is a 95% probability that its value is between 
</p>

<p>
\[
\overline{X}-1.96\frac{\sigma}{\sqrt{n}}
\]
</p>

<p>
and 
</p>

<p>
\[
\overline{X}+1.96\frac{\sigma}{\sqrt{n}}
\]
</p>

<p>
This interval
</p>

<p>
\[
\Biggl(\overline{X}-1.96\frac{\sigma}{\sqrt{n}}, \overline{X}+1.96\frac{\sigma}{\sqrt{n}}\Biggr)
\]
</p>

<p>
is called the <b>95% confidence interval</b> for \(\mu\).  
</p>


<p>
Example: Suppose we obtained \(\overline{x}=54\) from a sample of \(n=25\).  Suppose further that we know that the population is normal, with unknown mean \(\mu\), but known standard deviation \(\sigma=9\).  Construct a 95% confidence interval for the mean \(\mu\).
</p>

<p>
From above, we compute
</p>

<p>
\[
\Biggl(54 - 1.96\frac{9}{\sqrt{25}}, 54 + 1.96\frac{9}{\sqrt{25}}\Biggr) = (50.5,57.5)
\]
</p>

<p>
Thus, we are 95% confident that the population mean \(\mu\) is between 50.5 and 57.5
</p>
</div>


<div id="outline-container-sec-2-1-1" class="outline-4">
<h4 id="sec-2-1-1">General case:</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
There is nothing special about the quantity 95%.  We can compute any confidence interval we wish!
</p>

<p>
Example: For 16 observations randomly sampled from a normal distribution, imagine that \(\overline{X}=32\) and \(\sigma =4\).  Construct a 90% confidence interval for \(\mu\).
</p>

<p>
To construct a 90% interval, we must know the \(z\) scores that contain 90% of the standard normal distribution.  That is, we need to know the 0.05 quantile and the 0.95 quantile (this is because we need a total of 10% combined in the upper and lower tails).
</p>

<pre class="example">
qnorm(0.05)
qnorm(0.95)
</pre>

<p>
We see that the two quantiles for the 90% confidence interval are \(\pm 1.645\).  Thus, we can compute:
</p>

<p>
\[
\Biggl(32 - 1.645\frac{4}{\sqrt{16}}, 32 + 1.645\frac{4}{\sqrt{16}}\Biggr) = (30.355, 33.645)
\]
</p>

<p>
Thus, we are 95% confident that \(\mu\) is between 30.355 and 33.645.
</p>
</div>
</div>
</div>


<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2">Case 2: assume \(\sigma\) is NOT known</h3>
<div class="outline-text-3" id="text-2-2">
<p>
If \(\sigma\) is NOT known, we will need an <i>estimator</i> for it.
</p>

<p>
Recall that the definition of standard deviation is usually given as the square root of the variance, given by
</p>

<p>
\[
\frac{\sum (x-\mu)^2}{n}
\]
</p>

<p>
Unfortunately, this formula is well known to underestimate the actual value of the variance.  That is,
</p>

<p>
\[
E[\text{variance}] = \sigma^2 - \frac{\sigma^2}{n}
\]
</p>

<p>
However, if we adjust the formula for variance slightly to:
</p>

<p>
\[
s^2 = \frac{\sum (x-\mu)^2}{n-1}
\]
</p>

<p>
it can be shown that \(E[s^2] = \sigma^2\).  That is, \(s\) is an <i>unbiased</i> estimate of \(\sigma\).
</p>
</div>


<div id="outline-container-sec-2-2-1" class="outline-4">
<h4 id="sec-2-2-1">Student's \(T\) distribution</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
In 1908, William Gosset figured out how to quantify error when sampling from normal distributions from which the the standard deviation is <i>unknown</i>.  He published his work using the psuedonym "Student"
</p>


<div class="figure">
<p><img src="figures/week3/student.png" alt="student.png" />
</p>
</div>

<p>
Essentially, his method is based on computing something similar to the \(z\) score.  Let
</p>

<p>
\[
T=\frac{\overline{X}-\mu}{s/\sqrt{n}}
\]
</p>

<p>
Notice that the only difference from \(Z\) is that we have replaced \(\sigma\) by the unbiased estimator \(s\).
</p>

<p>
It turns out that the distribution \(T\) is NOT a normal distribution; moreover, its shape depends on the sample size \(n\).  Specifically, the parameter is <code>df</code> (degrees of freedom), where \(df=n-1\).
</p>

<p>
Executing the following R commands will produce a nice plot demonstrating this:
</p>

<pre class="example">
dev.off()
x=seq(-3,3,0.01)
plot(x,dnorm(x),type="l")
lines(x,dt(x,df=5),lty=2)
lines(x,dt(x,df=20),lty=3)
legend(0,0.1,c("normal","df=5","df=20"),lty=1:3)
</pre>

<p>
As you can see in the figure, the T curves have heavier tails than the normal curve.  As 
<img src="figures/week3/tDist.png" alt="tDist.png" />
</p>
</div>
</div>

<div id="outline-container-sec-2-2-2" class="outline-4">
<h4 id="sec-2-2-2">Computing confidence intervals with with \(T\)</h4>
<div class="outline-text-4" id="text-2-2-2">
<p>
When \(\sigma\) is not known, we can use the value of \(s\) as an estimate for the population standard deviation. However, as we just saw, the resulting sampling distribution \(T\) is not normal.  Thus, we can no longer use our old friend 1.96 to compute a 95% confidence interval.  We have to compute confidence intervals using different bounds.
</p>

<p>
Example:  Lets go back to our rats from above.  We tested 22 rats and got a sample mean of \(\overline{x}=11\).  Assume further that our sample standard deviation is \(s=19\).  Compute a 90% confidence interval for the population mean \(\mu\).
</p>

<p>
Similar to before, we will compute the interval
</p>

<p>
\[
\Biggl(\overline{X}-c\cdot \frac{s}{\sqrt{n}}, \overline{X}+c\cdot \frac{s}{\sqrt{n}}\Biggr)
\]
</p>

<p>
To find \(c\), we need to know the 0.05 and 0.95 quantiles of the \(T\) distribution on 21 degrees of freedom.
</p>

<pre class="example">
qt(0.05, df=21)
qt(0.95, df=21)
</pre>

<p>
Thus, we see that our interval is:
</p>

<p>
\[
\Biggl(11-1.72\cdot \frac{19}{\sqrt{22}}, 11+1.72\cdot \frac{19}{\sqrt{22}}\Biggr) = (4.03, 17.97)
\]
</p>

<p>
Example:  Suppose we test a new reading instruction method on 4th graders and obtain the following scores on a reading test: 
</p>

<p>
12, 20, 34, 45, 34, 36, 37, 50, 11, 32, 29
</p>

<p>
Suppose further that the <i>standard</i> methods of reading instructions produce an average score on this test of 25.  Does the new reading method increase reading scores?
</p>

<p>
To answer this, we will compute a 95% confidence interval for \(\mu\), the population of reading scores under this NEW method:
</p>

<pre class="example">
read=c(12,20,34,45,34,36,37,50,11,32,29)

length(read) # easy way to compute sample size

Xbar=mean(read)
s=sd(read)

c=qt(0.975,df=10) # compute 0.975 quantile

Xbar-c*s/sqrt(10) # lower limit
Xbar+c*s/sqrt(10) # upper limit
</pre>

<p>
We can see that our 95% confidence interval is (22.2,39.6).  Since this interval contains 25, we are not confident that the new reading method increases reading scores.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">What happens when sampling from non-normal distribution?</h2>
<div class="outline-text-2" id="text-3">
<p>
Everything we've done so far <b>assumes</b> that the underlying distribution is normal.  However, this is surely not the case.  Thankfully, we have some powerful mathematical results at our disposal that should help to quell our fears!
</p>
</div>
<div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1">Central limit theorem - if \(n\) is large enough, \(Z\) has standard normal distribution</h3>
<div class="outline-text-3" id="text-3-1">
<p>
This does leave a pressing question: how large must \(n\) be?
</p>

<p>
There is no simple answer. Lets investigate:
</p>

<p>
<b>Case 1 &#x2013; assume population comes from <i>uniform</i> distribution</b>
</p>

<pre class="example">
N=5000
Xbar=rep(0,N)
for (i in 1:N){
  Xsamp=runif(n=20, min=0, max=1)
  Xbar[i]=mean(Xsamp)
}

par(mfrow=c(2,1))
x=seq(0,1,0.01)
plot(x, dunif(x, min=0, max=1), type="l")
plot(density(Xbar))
</pre>


<div class="figure">
<p><img src="figures/week3/uniform.png" alt="uniform.png" />
</p>
</div>

<p>
As you can see, the distribution of samples looks fairly normal
</p>

<p>
<b>Case 2 &#x2013; assume population comes from <i>exponential</i> distribution</b>
</p>

<pre class="example">
N=5000
Xbar=rep(0,N)
for (i in 1:N){
  Xsamp=rexp(n=20, rate=1)
  Xbar[i]=mean(Xsamp)
}

x=seq(0,1,0.01)
plot(x, dexp(x, rate=1), type="l")
plot(density(Xbar))
</pre>


<div class="figure">
<p><img src="figures/week3/exponential.png" alt="exponential.png" />
</p>
</div>

<p>
Once again, the sampling distribution looks pretty normal, even with relatively small sample size (\(n=20\))
</p>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2">Is \(T\) distribution robust?</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Recall that confidence intervals based on \(T\) scores assume normality.  How <i>robust</i> is the \(T\) distribution to violations of this assumption?
</p>

<ul class="org-ul">
<li><b>Case 1: heavy tailed distributions</b>
</li>
</ul>

<p>
Let's simulate a <i>contaminated normal</i> distribution.  This is a distribution where scores come from two different underlying normal distributions.  In this case, we'll model the case where both distributions have the same mean, but different standard deviations.
</p>

<p>
First, we define a function in R to randomly generate scores from such a beast:
</p>

<pre class="example">
rcnorm &lt;- function(n,mean,sd1,sd2,prob){
  x0 = rnorm(n, mean, sd=sd1)
  x1 = rnorm(n, mean, sd=sd2)
  flag = rbinom(n, size=1, prob)
  return(x0*(1-flag) + x1*flag)
}
</pre>

<p>
Now, we will do as above and draw 5000 samples of size 20, computing the T-score each time and then plotting the resulting sampling distribution compared to a theoretical \(T\) distribution.
</p>

<pre class="example">
dev.off()
N=5000
T=rep(0,N)
for (i in 1:N){
  samp=rcnorm(n=20, mean=50, sd1=3, sd2=10, prob=0.5)
  T[i]=(mean(samp)-50)/(sd(samp)/sqrt(20))
}

x=seq(-4,4,0.01)
plot(density(T))
lines(x,dt(x,df=19),lty=2)
</pre>


<div class="figure">
<p><img src="figures/week3/contaminated.png" alt="contaminated.png" />
</p>
</div>

<p>
As you can see, our empirical distribution of \(T\) scores (solid line) looks similar to the theoretical \(T\) distribution that assumes normality (dashed line).  However, they are slightly different, as we can see with quantile calculations:
</p>

<pre class="example">
qt(c(0.025,0.975),df=19)
</pre>

<p>
In the theoretical \(T\) distribution, 95% of the \(t\) scores are between -2.09 and 2.09.
</p>

<pre class="example">
sum(T&gt;-2.09 &amp; T&lt;2.09)/5000
</pre>

<p>
However, in our empirical distribution, this same range accounts for almost 96% of our \(t\) scores.  The fact that they do not match may not bode well for more serious violations of normality.
</p>

<ul class="org-ul">
<li><b>Case 2: skewed distributions</b>
</li>
</ul>

<p>
As a last demonstration, lets take the case where the underlying distribution has a skew.  One such distribution is the <i>lognormal</i> distribution.
</p>

<p>
First, let's try a small sample (\(n=20\)):
</p>

<pre class="example">
# some stuff that you need to make it work!
m &lt;- 20
s &lt;- 10
location &lt;- log(m^2 / sqrt(s^2 + m^2))
shape &lt;- sqrt(log(1 + (s^2 / m^2)))

# small sample: n=20
N=5000
T=rep(0,N)
for (i in 1:N){
  samp=rlnorm(n=20, meanlog=location, sdlog=shape)
  T[i]=(mean(samp)-m)/(sd(samp)/sqrt(20))
}

par(mfrow=c(2,1))
x=seq(0,50,0.01)
plot(x,dlnorm(x,meanlog=location,sdlog=shape),type="l")
plot(density(T))
</pre>


<div class="figure">
<p><img src="figures/week3/lognormal.png" alt="lognormal.png" />
</p>
</div>

<p>
As you can see in the figure, the distribution of \(T\) scores no longer appears symmetric about 0.  We can verify this fact with a quantile calculation for our empirical distribution:
</p>

<pre class="example">
quantile(T,probs=c(0.025, 0.975))
</pre>

<p>
In fact, if we use the <i>usual</i> computation for a 95% interval (i.e., (-2.09, 2.09), we only get about 93% coverage (as verified in the following computation):
</p>

<pre class="example">
sum(T&gt;-2.09 &amp; T&lt;2.09)/5000
</pre>


<p>
Does it get better with a large sample?  Lets find out with \(n=200\):
</p>

<pre class="example">
N=5000
T=rep(0,N)
for (i in 1:N){
  samp=rlnorm(n=200, meanlog=location, sdlog=shape)
  T[i]=(mean(samp)-m)/(sd(samp)/sqrt(200))
}

x=seq(0,50,0.01)
plot(x,dlnorm(x,meanlog=location,sdlog=shape),type="l")
plot(density(T))
</pre>


<div class="figure">
<p><img src="figures/week3/lognormal2.png" alt="lognormal2.png" />
</p>
</div>

<p>
Looks better.  Lets verify.
</p>

<pre class="example">
quantile(T, probs=c(0.025, 0.975))
sum(T&gt;-2.09 &amp; T&lt;2.09)/5000
</pre>

<p>
As you can see, though better, our empirical distribution of \(T\) scores is not equivalent to the theoretical distribution.
</p>

<p>
<b>Moral</b>: contrary to what you might hear, the \(t\)-score is NOT robust to violations of normality!
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Date: September 11, 2017</p>
<p class="date">Created: 2017-10-31 Tue 10:41</p>
<p class="creator"><a href="http://www.gnu.org/software/emacs/">Emacs</a> 25.2.1 (<a href="http://orgmode.org">Org</a> mode 8.2.10)</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
