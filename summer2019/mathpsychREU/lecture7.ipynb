{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lecture7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomfaulkenberry/courses/blob/master/summer2019/mathpsychREU/lecture7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDNxWqEngt8b",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 7 - The ex-Gaussian model for RTs\n",
        "\n",
        "Recall from last time that we would like to model RT as a sum of two random variables D and M, where\n",
        "* $M \\sim \\text{Normal}(\\mu,\\sigma)$\n",
        "* $D \\sim \\text{Exponential}(\\lambda)$\n",
        "\n",
        "These random variables have associated probability density functions:\n",
        "* $f(t\\mid \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\Bigl( -\\frac{(t-\\mu)^2}{2\\sigma^2}\\Bigr)$\n",
        "* $g(t\\mid \\lambda) = \\lambda e^{-\\lambda t}$\n",
        "\n",
        "Then, the probability density for $RT = D+M$ is given by the *convolution* of $f$ and $g$, defined as:\n",
        "\n",
        "$$\n",
        "f_{EG}(t\\mid \\mu,\\sigma,\\lambda) = \\int_{-\\infty}^t f(x)g(t-x)dx\n",
        "$$\n",
        "\n",
        "Let's see that the convolution works in principle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfjrd8OgL917",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm, expon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VIDiYOKMg9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T = np.linspace(0,600,200)\n",
        "\n",
        "plt.plot(T, norm.pdf(T, loc=300, scale=50))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-EkytNHNM3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(T, expon.pdf(T, scale=100))\n",
        "plt.show()\n",
        "\n",
        "# note: scale = 1/lambda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60U3T3YtNVCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = norm.pdf(T, loc=300, scale=50)\n",
        "g = expon.pdf(T, scale=100)\n",
        "fg = np.convolve(f,g)\n",
        "\n",
        "plt.plot(fg)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2dejmFTN3b0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's use built in ex-Gaussian density from Python (thanks Nicholas!)\n",
        "\n",
        "from scipy.stats import exponnorm\n",
        "\n",
        "plt.plot(T, exponnorm.pdf(T, loc=200, scale=50, K=2))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjqAAyVhmfWJ",
        "colab_type": "text"
      },
      "source": [
        "## Note about parameterizations:\n",
        "\n",
        "Different authors will use different parameterizations of the ex-Gaussian density.  I prefer using the one used by Matzke & Wagenmakers (2009), which involves the following three parameters:\n",
        "* $\\mu$ = expected value of the normal component\n",
        "* $\\sigma$ = standard deviation of normal component\n",
        "* $\\tau$ = expected value of the exponential (tail) component\n",
        "\n",
        "The density function is given by:\n",
        "\n",
        "$$\n",
        "f(t\\mid \\mu, \\sigma, \\tau) = \\frac{1}{\\tau \\sqrt{2\\pi}}\\exp\\Bigl(\\frac{\\sigma^2}{2\\tau^2}-\\frac{x-\\mu}{\\tau}\\Bigr)\\int_{-\\infty}^{[(x-\\mu)/\\sigma]-(\\sigma/\\tau)}\\exp \\Bigl( -\\frac{y^2}{2}\\Bigr)dy\n",
        "$$\n",
        "\n",
        "One advantage of this parameterization is that we have the following:\n",
        "* $E(t)=\\mu+\\tau$\n",
        "* $Var(t) = \\sigma^2+\\tau^2$\n",
        "\n",
        "implying that the overall mean (and variance) of our RT distribution can be thought of as \"decomposed\" into a \"normal mean\" and a \"tail mean\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJo1R-QQnQnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in Python, this is equivalent to the following:\n",
        "#\n",
        "# mu = loc\n",
        "# sigma = scale\n",
        "# tau = K*sigma\n",
        "\n",
        "# we can now define the NLL for the ex-Gaussian\n",
        "# first, let's load our data:\n",
        "dat = pd.read_csv(\"https://raw.githubusercontent.com/tomfaulkenberry/courses/master/summer2019/mathpsychREU/schwarz-A.csv\")\n",
        "X = dat.RT\n",
        "\n",
        "def nllEG(pars):\n",
        "  mu, sigma, tau = pars\n",
        "  ll = np.log(exponnorm.pdf(X, loc=mu, scale=sigma, K=tau/sigma))\n",
        "  return(-1*sum(ll))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8bjqHOqoRMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test our nllEG function\n",
        "\n",
        "pars=np.array([200, 50, 100])\n",
        "nllEG(pars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VCMSy2IovJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# minimize the NLL against observed RTs\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from scipy.stats import skew\n",
        "\n",
        "# init recommendations from Lacouture & Cousineau (2008)\n",
        "\n",
        "tau_init = 0.8*X.std()\n",
        "mu_init = X.mean()-skew(X)\n",
        "sigma_init = np.sqrt(X.var()-tau_init**2)\n",
        "\n",
        "# store init parameters as numpy array\n",
        "inits = np.array([mu_init, sigma_init, tau_init])\n",
        "\n",
        "mleEG = minimize(fun = nllEG, \n",
        "               x0 = inits,\n",
        "               method = 'nelder-mead')\n",
        "\n",
        "print(mleEG)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKDh0ngUnbv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check that overall mean is decomposed into mu + tau\n",
        "\n",
        "print(X.mean())\n",
        "print(mleEG.x[0]+mleEG.x[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvTmU0c5pMs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets plot against our observed data\n",
        "\n",
        "plt.hist(X, bins=np.linspace(100, 600, 25), density=True, color='lightgray')\n",
        "\n",
        "# extract fit and plot it\n",
        "mu, sigma, tau = mleEG.x\n",
        "\n",
        "T = np.linspace(100,600,100)\n",
        "plt.plot(T, exponnorm.pdf(T, loc=mu, scale=sigma, K=tau/sigma))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pkpazj42phCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# compare to normal fit from last time\n",
        "\n",
        "# construct NLL for normal\n",
        "def nllNormal(pars):\n",
        "  mu, sigma = pars\n",
        "  ll = np.log(norm.pdf(X, loc=mu, scale=sigma))\n",
        "  return(-1*np.sum(ll))\n",
        "  \n",
        "mu_init = X.mean()\n",
        "sigma_init = X.std()\n",
        "\n",
        "# store init parameters as numpy array\n",
        "inits = np.array([mu_init, sigma_init])\n",
        "\n",
        "mleNormal = minimize(fun = nllNormal, \n",
        "               x0 = inits,\n",
        "               method = 'nelder-mead')\n",
        "\n",
        "\n",
        "plt.hist(X, bins=np.linspace(100, 600, 25), density=True, color='lightgray')\n",
        "\n",
        "# extract normal fit and plot\n",
        "mean, sd = mleNormal.x\n",
        "plt.plot(T, norm.pdf(T, loc=mean, scale=sd), '--')\n",
        "\n",
        "# extract ex-Gaussian fit and plot it\n",
        "mu, sigma, tau = mleEG.x\n",
        "\n",
        "T = np.linspace(100,600,100)\n",
        "plt.plot(T, exponnorm.pdf(T, loc=mu, scale=sigma, K=tau/sigma))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__eZyC2HqL-A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get ex-Gaussian parameters\n",
        "mu, sigma, tau = mleEG.x\n",
        "print(mu)\n",
        "print(sigma)\n",
        "print(tau)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItMrEnZNqYkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use bootstrapping to get 95% confidence interval on parameters\n",
        "\n",
        "# first, define a function to do MLE and return parameters\n",
        "\n",
        "def fitEG(x):\n",
        "  \n",
        "  # computed nll\n",
        "  def nllEG(pars):\n",
        "    mu, sigma, tau = pars\n",
        "    ll = np.log(exponnorm.pdf(x, loc=mu, scale=sigma, K=tau/sigma))\n",
        "    return(-1*np.sum(ll))\n",
        "  \n",
        "  # minimize the nll\n",
        "  tau_init = 0.8*x.std()\n",
        "  mu_init = x.mean()-skew(x)\n",
        "  sigma_init = np.sqrt(x.var()-tau_init**2)\n",
        "\n",
        "  # store init parameters as numpy array\n",
        "  inits = np.array([mu_init, sigma_init, tau_init])\n",
        "\n",
        "  mleEG = minimize(fun = nllEG, \n",
        "                   x0 = inits,\n",
        "                   method = 'nelder-mead')\n",
        "  \n",
        "  # return fit object\n",
        "  return mleEG.x[0], mleEG.x[1], mleEG.x[2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQgyRdforbuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now, we do the bootstrapping\n",
        "\n",
        "# set number of bootstrap samples\n",
        "N = 100\n",
        "\n",
        "# set seed for reproducibility\n",
        "np.random.seed(122)\n",
        "\n",
        "# obtain the original model fit\n",
        "mu, sigma, tau = fitEG(X)\n",
        "\n",
        "# set empty lists to store parameter values\n",
        "Mu = []\n",
        "Sigma = []\n",
        "Tau = []\n",
        "\n",
        "for i in range(N):\n",
        "  # generate new data\n",
        "  Xsim = exponnorm.rvs(size=len(X), loc=mu, scale=sigma, K=tau/sigma)\n",
        "  \n",
        "  # find MLE for mu, sigma, and tau\n",
        "  mu_bootstrap, sigma_bootstrap, tau_bootstrap = fitEG(Xsim)\n",
        "  \n",
        "  # append these estimates \n",
        "  Mu.append(mu_bootstrap)\n",
        "  Sigma.append(sigma_bootstrap)\n",
        "  Tau.append(tau_bootstrap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75ZNCmWBu17C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(Mu, color=\"lightgray\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(Sigma, color=\"lightgray\")\n",
        "plt.show()\n",
        "\n",
        "plt.hist(Tau, color=\"lightgray\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQr3V2aAv9kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.quantile(Mu, [0.025, 0.975]))\n",
        "print(np.quantile(Sigma, [0.025, 0.975]))\n",
        "print(np.quantile(Tau, [0.025, 0.975]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8IXgKRcwNr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# next step in modeling -- look at effects of experimental manipulations\n",
        "# Schwarz (2001) manipulated 'p_go' and 'd'\n",
        "\n",
        "dat.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIbw130swe-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Homework:\n",
        "# \n",
        "# your task is to find ex-Gaussian fits (and bootstrap confidence intervals) for each of the following conditions:\n",
        "# 1. p_go = 0.5 and d = 1\n",
        "# 2. p_go = 0.5 and d = 4\n",
        "# 3. p_go = 0.75 and d = 1\n",
        "# 4. p_go = 0.75 and d = 4\n",
        "\n",
        "# hint:  use the 'query' function from pandas\n",
        "\n",
        "example = dat.query('p_go == 0.5')\n",
        "\n",
        "example.head()\n",
        "example.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}